#version 450
#extension GL_KHR_shader_subgroup_basic : enable
#extension GL_KHR_shader_subgroup_ballot : enable
#extension GL_KHR_shader_subgroup_arithmetic : enable
#extension GL_KHR_shader_subgroup_vote : enable
#extension GL_KHR_shader_subgroup_shuffle_relative : enable
#extension GL_KHR_shader_subgroup_shuffle : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int64 : enable
#extension GL_EXT_shader_subgroup_extended_types_int64 : enable

#define RADIX_BIN 256
#define RADIX_LOG 8
#define RADIX_BITS 8
#define RADIX_MASK 255  // Mask of digit bins
#define RADIX_PASS 4    //(sizeof(uint) * 8 + RADIX_BITS - 1) / RADIX_BITS

#define LANE_COUNT 16  // number of threads in a subgroup
#define LANE_MASK 15
#define LANE_LOG 4

#define LANE gl_LocalInvocationID.x  // the idx of thread in the subgroup
#define SUBGROUP_IDX \
  gl_SubgroupID  // the idx of subgroup the thread belongs to might be wrong
#define SUBGROUP_THREAD_IDX \
  gl_GlobalInvocationID.x  //(LANE + (SUBGROUP_IDX << LANE_LOG)) // the subgroup
                           //relative thread idx

// For the binning
#define BIN_PART_SIZE \
  7680  // The partition tile size of a BinningPass threadblock
#define BIN_HISTS_SIZE \
  4096  // The total size of all subgroup histograms in shared memory
#define BIN_THREADS 512  // The number of threads in a BinningPass threadblock
#define BIN_SUB_PART_SIZE \
  240  // The subpartition tile size of a single subgroup in a BinningPass
       // threadblock
#define BIN_SUBGROUPS \
  32  // The number of subgroup in a BinningPass threadblock previously 16
#define BIN_KEYS_PER_THREAD \
  15  // The number of keys per thread in BinningPass threadblock previously 15

#define BIN_PARTITIONS \
  (n / BIN_PART_SIZE)  // The number of partition tiles in a BinningPass
#define BIN_SUB_PART_START \
  (SUBGROUP_IDX *          \
   BIN_SUB_PART_SIZE)  // The starting offset of a subpartition tile
#define BIN_PART_START \
  (partitionIndex * BIN_PART_SIZE)  // The starting offset of a partition tile
#define BIN_THREAD_BLOCKS (n + BIN_PART_SIZE - 1) / BIN_PART_SIZE

#define FLAG_NOT_READY \
  0  // Flag value inidicating neither inclusive sum, or aggregate sum of a
     // partition tile is ready
#define FLAG_AGGREGATE \
  1  // Flag value indicating aggregate sum of a partition tile is ready
#define FLAG_INCLUSIVE \
  2  // Flag value indicating inclusive sum of a partition tile is ready
#define FLAG_MASK 3  // Mask used to retrieve flag values

layout(set = 1, binding = 0) buffer BSortBuffer { uint b_sort[]; };

layout(set = 1, binding = 2) buffer BAltBuffer { uint b_alt[]; };

layout(set = 1, binding = 1) buffer BGlobalHist { uint b_globalHist[1024]; };

layout(set = 1, binding = 3) coherent buffer BIndex { uint b_index[4]; };

layout(set = 1, binding = 4) coherent buffer BPassHist { uvec4 b_passHist[]; };

layout(push_constant) uniform Params {
  uint pass_num;
  uint radix_shift;
  uint n;
};

layout(local_size_x = 512) in;

shared uint s_subgroupHistograms[BIN_PART_SIZE];
shared uint s_localHistograms[RADIX_BIN];

uint InclusiveWarpScanCircularShift(uint val) {
  for (uint i = 1; i <= (LANE_COUNT >> 1); i <<= 1) {
    const uint t = subgroupShuffleUp(val, i);
    if (gl_SubgroupInvocationID >= i) val += t;
  }
  return subgroupShuffle(val,
                         (gl_SubgroupInvocationID + LANE_MASK) & LANE_MASK);
}

uint ActiveExclusiveWarpScan(uint val) {
  uint result = 0;
  for (uint i = 1; i <= (LANE_COUNT >> 1); i <<= 1) {
    uint t = subgroupShuffleUp(val, i);
    if (gl_SubgroupInvocationID >= i) val += t;
  }
  const uint t = subgroupShuffleUp(val, 1);
  return (gl_SubgroupInvocationID > 0) ? t : 0;
}

uint64_t getLaneMaskLt() {
  uint laneId = gl_SubgroupInvocationID;
  uint64_t mask = 0;

  // Generate the mask dynamically based on the current laneId
  // For each bit position less than laneId, set the corresponding bit in mask
  for (uint i = 0; i < laneId; ++i) {
    mask |= (1u << i);
  }

  return mask;
}

void k_DigitBinning(uint zheyuan_block_id, uint logical_blocks) {
  // clear shared memory
  for (uint i = gl_LocalInvocationID.x; i < BIN_HISTS_SIZE;
       i += gl_WorkGroupSize.x) {
    s_subgroupHistograms[i] = 0;
  }

  // assign partition tiles
  if (gl_LocalInvocationID.x == 0)
    s_subgroupHistograms[BIN_PART_SIZE - 1] =
        atomicAdd(b_index[radix_shift >> 3], 1);
  groupMemoryBarrier();
  barrier();

  const uint partitionIndex = s_subgroupHistograms[BIN_PART_SIZE - 1];

  // load global histogram into shared memory
  if (gl_LocalInvocationID.x < RADIX_BIN)
    s_localHistograms[gl_LocalInvocationID.x] =
        b_globalHist[gl_LocalInvocationID.x + (radix_shift << 5)];

  // handle size that is not prect multiple of parition size
  if (partitionIndex < logical_blocks - 1) {
    // load the keys
    uint keys[BIN_KEYS_PER_THREAD];
    for (uint i = 0,
              t = gl_SubgroupInvocationID + BIN_SUB_PART_START + BIN_PART_START;
         i < BIN_KEYS_PER_THREAD;
         i++, t += LANE_COUNT) {
      keys[i] = pass_num % 2 == 0 ? b_sort[t] : b_alt[t];
    }

    uint _offsets[BIN_KEYS_PER_THREAD];

    // warp level mutli-split
    for (uint i = 0; i < BIN_KEYS_PER_THREAD; ++i) {
      uint warpFlags_x = 0xFFFFFFFF;
      uint warpFlags_y = 0xFFFFFFFF;
      for (int k = 0; k < RADIX_LOG; ++k) {
        const bool t2 = (keys[i] >> k + radix_shift & 1) > 0;
        uvec4 ballot = subgroupBallot(t2);
        warpFlags_x &= (t2 ? 0 : 0xFFFFFFFF) ^ ballot.x;
        warpFlags_y &= (t2 ? 0 : 0xFFFFFFFF) ^ ballot.y;
      }

      // Number of peers having same digit as key[i]
      // maybe it is wrong?
      uvec4 warpFlags = uvec4(warpFlags_x, warpFlags_y, 0, 0);
      const uint bits = subgroupBallotExclusiveBitCount(warpFlags);

      uint prev;
      if (bits == 0)
        prev = atomicAdd(
            s_subgroupHistograms[(gl_SubgroupID.x << RADIX_LOG) +
                                 ((keys[i] >> radix_shift) & RADIX_MASK)],
            bitCount(warpFlags_x) + bitCount(warpFlags_y));

      _offsets[i] =
          subgroupShuffle(prev, subgroupBallotFindLSB(warpFlags)) + bits;
    }

    groupMemoryBarrier();
    barrier();

    // exclusive prefix scan up the  warp histograms
    if (gl_LocalInvocationID.x < RADIX_BIN) {
      uint reduction = s_subgroupHistograms[gl_LocalInvocationID.x];
      for (uint i = gl_LocalInvocationID.x + RADIX_BIN; i < BIN_HISTS_SIZE;
           i += RADIX_BIN) {
        reduction += s_subgroupHistograms[i];
        s_subgroupHistograms[i] = reduction - s_subgroupHistograms[i];
      }
      // uint val = ((partitionIndex > 0) ? FLAG_AGGREGATE : FLAG_INCLUSIVE) |
      // reduction << 2;
      atomicAdd(b_passHist[gl_LocalInvocationID.x * logical_blocks +
                           partitionIndex][pass_num],
                ((partitionIndex > 0) ? FLAG_AGGREGATE : FLAG_INCLUSIVE) |
                    (reduction << 2));
      // exclusive prefix sum across reduction
      s_subgroupHistograms[gl_LocalInvocationID.x] =
          InclusiveWarpScanCircularShift(reduction);
    }
    groupMemoryBarrier();
    barrier();

    if (gl_LocalInvocationID.x < (RADIX_BIN >> LANE_LOG))
      s_subgroupHistograms[gl_LocalInvocationID.x << LANE_LOG] =
          subgroupExclusiveAdd(
              s_subgroupHistograms[gl_LocalInvocationID.x
                                   << LANE_LOG]);  // ActiveExclusiveWarpScan(s_subgroupHistograms[gl_LocalInvocationID.x
                                                   // << LANE_LOG]);
    groupMemoryBarrier();
    barrier();

    if ((gl_LocalInvocationID.x < RADIX_BIN) && (gl_SubgroupInvocationID) > 0)
      s_subgroupHistograms[gl_LocalInvocationID.x] += subgroupBroadcast(
          s_subgroupHistograms[gl_LocalInvocationID.x - 1], 1);  // or
                                                                 // subgroupShuffle(s_subgroupHistograms[gl_LocalInvocationID.x],
                                                                 // 1)
    groupMemoryBarrier();
    barrier();

    // update offsets
    if (gl_SubgroupID > 0) {
      for (uint i = 0; i < BIN_KEYS_PER_THREAD; ++i) {
        const uint t2 = keys[i] >> radix_shift & RADIX_MASK;
        _offsets[i] += s_subgroupHistograms[(gl_SubgroupID << RADIX_LOG) + t2] +
                       s_subgroupHistograms[t2];
      }
    } else {
      for (uint i = 0; i < BIN_KEYS_PER_THREAD; ++i) {
        _offsets[i] +=
            s_subgroupHistograms[keys[i] >> radix_shift & RADIX_MASK];
      }
    }

    // split the warps into single thread cooperative groups and lookback
    if (gl_LocalInvocationID.x < RADIX_BIN) {
      if (partitionIndex > 0) {
        uint reduction = 0;
        for (int k = int(partitionIndex); k > 0;) {
          const uint flagPayload =
              b_passHist[gl_LocalInvocationID.x * logical_blocks + k - 1]
                        [pass_num];

          if ((flagPayload & FLAG_MASK) == FLAG_INCLUSIVE) {
            reduction += flagPayload >> 2;
            atomicAdd(b_passHist[gl_LocalInvocationID.x * logical_blocks +
                                 partitionIndex][pass_num],
                      1 | (reduction << 2));
            s_localHistograms[gl_LocalInvocationID.x] +=
                reduction - s_subgroupHistograms[gl_LocalInvocationID.x];
            break;
          }

          if ((flagPayload & FLAG_MASK) == FLAG_AGGREGATE) {
            reduction += flagPayload >> 2;
            k--;
          }
        }

      } else {
        s_localHistograms[gl_LocalInvocationID.x] -=
            s_subgroupHistograms[gl_LocalInvocationID.x];
      }
    }

    groupMemoryBarrier();
    barrier();

    // scatter keys into shared memory
    for (uint i = 0; i < BIN_KEYS_PER_THREAD; ++i) {
      s_subgroupHistograms[_offsets[i]] = keys[i];
    }
    groupMemoryBarrier();
    barrier();

    // scatter keys into device memory
    for (uint i = gl_LocalInvocationID.x; i < BIN_PART_SIZE;
         i += gl_WorkGroupSize.x) {
      pass_num % 2 == 0
          ? b_alt[s_localHistograms[s_subgroupHistograms[i] >> radix_shift &
                                    RADIX_MASK] +
                  i] = s_subgroupHistograms[i]
          : b_sort[s_localHistograms[s_subgroupHistograms[i] >> radix_shift &
                                     RADIX_MASK] +
                   i] = s_subgroupHistograms[i];
    }
  }

  // process final partition
  if (partitionIndex == logical_blocks - 1) {
    groupMemoryBarrier();
    barrier();

    if (partitionIndex > 0) {
      // lookback
      if (gl_LocalInvocationID.x < RADIX_BIN) {
        uint reduction = 0;
        for (int k = int(partitionIndex); k > 0;) {
          const uint flagPayload =
              b_passHist[gl_LocalInvocationID.x * logical_blocks + k - 1]
                        [pass_num];

          if ((flagPayload & FLAG_MASK) == FLAG_INCLUSIVE) {
            reduction += flagPayload >> 2;
            s_localHistograms[gl_LocalInvocationID.x] += reduction;
            break;
          }

          if ((flagPayload & FLAG_MASK) == FLAG_AGGREGATE) {
            reduction += flagPayload >> 2;
            k--;
          }
        }
      }
      groupMemoryBarrier();
      barrier();
    }

    const uint partEnd = BIN_PART_START + BIN_PART_SIZE;
    for (uint i = gl_LocalInvocationID.x + BIN_PART_START; i < partEnd;
         i += gl_WorkGroupSize.x) {
      uint key;
      uint offset;
      uint warpFlags_x = 0xFFFFFFFF;
      uint warpFlags_y = 0xFFFFFFFF;

      if (i < n) key = pass_num % 2 == 0 ? b_sort[i] : b_alt[i];

      for (uint k = 0; k < RADIX_LOG; ++k) {
        const bool t = (key >> k + radix_shift & 1) > 0;
        uvec4 ballot = subgroupBallot(t);
        warpFlags_x &= (t ? 0 : 0xFFFFFFFF) ^ ballot.x;
        warpFlags_y &= (t ? 0 : 0xFFFFFFFF) ^ ballot.y;
      }

      uvec4 warpFlags = uvec4(warpFlags_x, warpFlags_y, 0, 0);
      const uint bits = subgroupBallotExclusiveBitCount(
          uvec4(warpFlags_x, warpFlags_y, 0, 0));

      for (uint k = 0; k < BIN_SUBGROUPS; ++k) {
        uint prev;
        if (gl_SubgroupID.x == k && bits == 0 && i < n) {
          prev = atomicAdd(s_localHistograms[key >> radix_shift & RADIX_MASK],
                           bitCount(warpFlags_x) + bitCount(warpFlags_y));
        }
        if (gl_SubgroupID.x == k) {
          offset =
              subgroupShuffle(prev, subgroupBallotFindLSB(warpFlags)) + bits;
        }
        groupMemoryBarrier();
        barrier();
      }

      if (i < n) pass_num % 2 == 0 ? b_alt[offset] = key : b_sort[offset] = key;
    }
  }
}

void main() {
  uint logical_blocks = uint(ceil(float(n) / float(BIN_PART_SIZE)));
  for (uint zheyuan_block_id = gl_WorkGroupID.x;
       zheyuan_block_id < logical_blocks;
       zheyuan_block_id += gl_NumWorkGroups.x) {
    if (zheyuan_block_id < logical_blocks) {
      k_DigitBinning(zheyuan_block_id, logical_blocks);
    }
  }
}